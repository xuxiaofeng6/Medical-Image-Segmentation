#DATA
data_root:
classes: 2
modality: MRA


#MODEL
arch: attention_unet
in_chan: 1
base_chan: 32
down_scale: [[2,2,2], [2,2,2], [2,2,2], [2,2,2]]
kernel_size: [[3,3,3], [3,3,3], [3,3,3], [3,3,3], [3,3,3]]
block: BasicBlock
norm: in

#TRAIN
epochs: 500
training_size: [128, 128, 128] # training crop size
start_epoch: 0

seed: 0
#k_fold: 5

optimizer: adamw
base_lr: 0.001
betas: [0.9, 0.999]
weight_decay: 0.05  # weight decay of SGD optimizer
weight: [0.5, 1]  # weitght of each class in the loss function
rlt: 1 # relation between CE and Dice loss

scale: [0.3, 0.3, 0.3]  # scale for data augmentation  0.1 0.3 0.3
rotate: [30, 30, 30] # rotation angle for data augmentation 
translate: [0, 0, 0]
gaussian_noise_std: 0.02


iter_per_epoch: 100
print_freq: 1

#VALIDATION
ema: True
ema_alpha: 0.99
val_frequency: 10


#INFERENCE
sliding_window: True
window_size: [128, 128, 128]
